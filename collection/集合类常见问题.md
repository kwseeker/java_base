# 集合类常见问题

## 接口类 

### 核心接口
```
Collection
  List
  Set
    SortedSet
  Queue
    Deque
Map
  SortedMap
```

### 辅助接口

```java
//用于自定义比较器，也可以在容器类内部以内部类定义
Comparator
//用于被容器类实现在容器类内部实现比较
Comparable
//通常在容器类内部以内部类的形式定义迭代器
Iterator
//被容器类直接实现迭代方法
Enumeration
//观察者模式，实现监听器，注册到监听者的监听器容器，条件满足后依次回调监听者方法
EventListener
//只是标识接口(intanceof区分)表明此类支持快速随机访问，实现此接口的类的数据处理可能和未实现此接口的类不同，参考下面分析
RandomAccess
  RandomAccessFile (C)
//并行遍历（1.8引入）,原理是将下标分成几个区间，使用多个线程遍历。
Spliterator
```

#### 随机访问(RandomAccess)

通过`grep -rins "instanceof RandomAccess" ./`检索JDK源码, 发现只有下面几个地方用到这个接口。
```
/share/classes/com/sun/imageio/spi/RAFImageOutputStreamSpijava
/share/classes/com/sun/imageio/spi/RAFImageInputStreamSpi.java
/share/classes/java/util/concurrent/ForkJoinTask.java
/share/classes/java/util/AbstractList.java
/share/classes/java/util/Collections.java
```

以Collections$binarySearch(List<? extends Comparable<? super T>>, T)为例分析（使用二分法查找目标元素在list中的位置）。  
注意binarySearch()只负责查不负责排序但二分查找的前提是元素有序。
```java
if (list instanceof RandomAccess || list.size() < BINARYSEARCH_THRESHOLD)
    // !!! ArrayList支持随机访问直接以[0,size)作为索引检索数据，然后进行比较
    // !!! LinkedList不支持随机访问但数据量比较小的话还是走的这个方法，但是内部处理和ArrayList完全不一样（从头开始向后next mid次）。
    return Collections.indexedBinarySearch(list, key);
else
    //不支持随机访问且size不小心于BINARYSEARCH_THRESHOLD，需要借助iterator检索数据，然后进行比较
    return Collections.iteratorBinarySearch(list, key);
```
分析上面JDK源码，发现和Collections一样，RandomAccess对数据的访问都**基于数组，然后可以通过索引、位移对数据快速地检索**。

HashMap、TreeMap为何也支持随机访问？
　
#### Enumeration和Iterator原理

Iterator.add()?

ListIterator?

### 设计思想

#### fail-fast与fail-safe

通过修改计数 modCount 实现。  
fail-fast是发现modCount和迭代前不一样直接返回ConcurrentModificationException；  
fail-safe是

#### Map.Entry<K,V>

#### 很多容器类将长度设置为２的幂次方

因为经常需要求hash然后计算存储位置，而取模运算％没有移位运算>>计算效率高。

## 常用类实现原理及设计思想分析

研究容器类要注意研究哪些内容：  
1) 容器类的数据结构以及使用这种数据结构的原因
2) 线程安全性
3) 自动扩容原理
4) 迭代器原理（Enumeration、Iterator）
5) 快速失败和安全失败
6) Comparable和Comparator  
  Comparator接口用于实现自己的比较器，Comparable由类继承在类实现时固定实现。
7) 随机存储

### JU包集合类

+ **ArrayList**

  1. 基于数组实现；
  2. 非线程安全；
  3. 默认无参构造容量为０（首次扩容为10），当数组已满继续插入则会扩容为之前的1.5倍空间，如果容量大于int最大值-8将容量拓展到int最大值。然后将数据从旧数组拷贝到新数组，并将新元素插入新的数组。
  4. 此迭代器实现比较简单，通过指针与元素个数比较，判断是否还有值未被遍历到。　　
  5. 当iterator操作中判断到modCount和初始值不同时，会抛出异常，即fast-fail。所有JU包中的非线程安全的集合都是fast-fail的。
  6. 排序基于`Arrays.sort(a, (Comparator) c)`，使用TimSort即归并排序，关于归并排序查看数据结构与算法相关总结。
  7. 基于数组实现支持随机访问。

+ **BitSet**

+ **HashMap**

  1. 刚开始当数据量较小时使用Hash桶（外边数组＋内部链表(存储碰撞数据)），
  当某个链表碰撞数据量超过８且外部数组容量超过64后将链表转换为红黑树（外边数组＋内部红黑树（存储碰撞数据））。  
     需要注意的是扩容是通过所有元素的个数作为指标的,而容量是通过外边数组计算的。  
     可以通过修改Class的hashcode()让插入数据大量冲突从而测试HashMap红黑树转换的过程。
  2. 非线程安全
  3. 当数据量达到容量的0.75,或者某个链表冲突数据大于８而数组容量小于64时触发扩容１倍。
  4. 迭代
  5. fast-fail

  **源码解析**：

  制造hash碰撞
  ```java
  @Test
  public void testHashMapCollision() {
      HashMap<MyObject, Integer> map = new HashMap<>();
      //需要确保hashCode相同但是对象不相同
      System.out.println(new MyObject().equals(new MyObject()));
      for (int i = 0; i < 200; i++) {
          map.put(new MyObject(), i);
      }
  }
  public static class MyObject {
      @Override
      public int hashCode() {
          return 1;
      }
  }
  ```
  HashMap数据插入流程
  ```java
  //1 插入第一个元素
  //  当插入第一个对象时，会进行扩容(容量16,下次扩容阈值12);
  newCap = DEFAULT_INITIAL_CAPACITY;
  newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
  //  创建哈希桶
  Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
  //  通过key计算hashcode & n-1得到存储位点，插入节点
  tab[i] = newNode(hash, key, value, null);
  //2 当插入第12个值后，resize(), 新建一个哈希桶，扩容１倍，下次扩容阈值32*0.75=24
  //  将原哈希桶的数据拷贝到新的哈希桶
  //3 随着插入数据越来越多，可能发生哈希碰撞，哈希碰撞后处理
  //  排除数据更新情况，只考虑插入新元素
  for (int binCount = 0; ; ++binCount) {
      if ((e = p.next) == null) {
          //新建节点插入到链表尾部
          p.next = newNode(hash, key, value, null);
          //这一步很重要：当链表长度大于８的时候，treeifyBin()
          if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
              treeifyBin(tab, hash);
          break;
      }
      //这个还是更新数据的操作（链表中的数据）
      if (e.hash == hash &&
          ((k = e.key) == key || (key != null && key.equals(k))))
          break;
      p = e;
  }
  //  当内部链表长度大于等于８时　treeifyBin()
  final void treeifyBin(Node<K,V>[] tab, int hash) {
      int n, index; Node<K,V> e;
      //并不是立马将链表转换为红黑树，而是还需要满足一个条件，tab的长度（外面hash桶的长度，不是元素个数）不小于MIN_TREEIFY_CAPACITY（64）。
      //否则还是选择扩容
      if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
          resize();
      else if ((e = tab[index = (n - 1) & hash]) != null) {
          TreeNode<K,V> hd = null, tl = null;
          //将之前的链表转换为红黑树
          do {
              TreeNode<K,V> p = replacementTreeNode(e, null);
              if (tl == null)
                  hd = p;
              else {
                  p.prev = tl;
                  tl.next = p;
              }
              tl = p;
          } while ((e = e.next) != null);
          if ((tab[index] = hd) != null)
              hd.treeify(tab);
      }
  }
  ```
  
+ **HashSet**

+ Hashtable

  1. 数组＋链表
  2. 线程安全的

+ **LinkedHashMap**

  1. `LinkedHashMap<K,V> extends HashMap<K,V>`, 说明和HashMap基本结构是相同的；LinkedHashMap在HashMap的基础上拓展了前后指针,相对于HashMap只是拓展了插入有序的功能，可以方便进行数据迭代。

      ```
      static class Entry<K,V> extends HashMap.Node<K,V> {
          Entry<K,V> before, after;
          Entry(int hash, K key, V value, Node<K,V> next) {
              super(hash, key, value, next);
          }
      }
      ```
  2. 非线程安全
  3. 扩容同HashMap
  4. 通过before、after指针（双向队列）遍历
  5. fail-fast

+ **LinkedHashSet**

+ **LinkedList**

  1. 基于链表;
  2. 非线程安全;
  3. 没有扩容一说
  4. 通过next指针。
  5. fast-fail
  6. 先`LinkedList$toArray()`将链表转换为数组，然后执行Arrays.sort()排序，即还是归并排序。
  7. 不支持随机存储。

+ Stack

+ **TreeMap**

  1. 直接基于红黑树实现（HashMap数据量大后，外边是数组（hash表）内部是红黑树）；使用key构造红黑树。所以对比两种数据结构，**TreeMap更适用于排序场景**，HashMap则没有排序；而HashMap在检索效率上相对TreeMap更高一些（插入效率由于HashMap自动扩容比较耗时间整体效率反而不确定了，经过简单测试HashMap插入效率比TreeMap好一点）。
  2. 非线程安全
  3. fast-fail
  4. 不支持随机存储

+ **TreeSet**

+ Vector

  和ArrayList相比是线程安全的，通过synchronized加锁实现。

### JUC包集合类



